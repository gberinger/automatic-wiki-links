Almost all these approaches normally work by defining a window of n content words around each word to be disambiguated in the corpus, and statistically analyzing those n surrounding words. Two shallow approaches used to train and then disambiguate are Na√Øve Bayes classifiers and decision *trees*. In recent research, kernel-based methods such as support vector machines have shown superior performance in supervised learning.